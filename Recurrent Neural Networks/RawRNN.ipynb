{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputString = [2,45,30,55,10]\n",
    "outputString = [45,30,55,10,1]\n",
    "numFeatures = 100 #Embedding Size\n",
    "vocabSize = 80 #Words available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [] #List of random Embeddings\n",
    "for i in range(len(inputString)):\n",
    "    x = np.random.randn(numFeatures,1) #Random Embedding\n",
    "    embeddings.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[-0.41644167],\n",
       "         [ 1.4572139 ],\n",
       "         [-2.09613552],\n",
       "         [ 0.44993645],\n",
       "         [ 0.43373268],\n",
       "         [-0.65288481],\n",
       "         [ 1.08985742],\n",
       "         [-1.32731822],\n",
       "         [-0.85311324],\n",
       "         [-0.6549107 ],\n",
       "         [-0.06563781],\n",
       "         [-0.14035496],\n",
       "         [-0.14781258],\n",
       "         [ 1.63290567],\n",
       "         [ 0.66386207],\n",
       "         [ 0.49313037],\n",
       "         [-0.81791479],\n",
       "         [-0.83306597],\n",
       "         [-0.66398429],\n",
       "         [-1.12629319],\n",
       "         [ 1.25167803],\n",
       "         [-2.32075385],\n",
       "         [ 1.03341746],\n",
       "         [ 0.77049461],\n",
       "         [ 2.85476441],\n",
       "         [-0.00637923],\n",
       "         [ 0.48444024],\n",
       "         [-0.00570254],\n",
       "         [ 0.35042009],\n",
       "         [ 1.05564339],\n",
       "         [-1.49156967],\n",
       "         [-0.89166366],\n",
       "         [-0.15370519],\n",
       "         [-0.2347041 ],\n",
       "         [-0.53921484],\n",
       "         [-0.06306569],\n",
       "         [-0.78370676],\n",
       "         [-0.47916896],\n",
       "         [-0.09174645],\n",
       "         [-0.19486551],\n",
       "         [-0.33787608],\n",
       "         [-0.48938893],\n",
       "         [ 1.36227577],\n",
       "         [-0.87183214],\n",
       "         [ 0.3681197 ],\n",
       "         [-0.73283525],\n",
       "         [ 0.29455366],\n",
       "         [ 0.12469279],\n",
       "         [-0.55698155],\n",
       "         [ 0.12987069],\n",
       "         [-1.47809269],\n",
       "         [ 0.19220134],\n",
       "         [ 0.68863988],\n",
       "         [-0.12046979],\n",
       "         [ 1.11687164],\n",
       "         [-1.21605588],\n",
       "         [-0.38606695],\n",
       "         [-0.76849875],\n",
       "         [-0.73184899],\n",
       "         [-0.46397906],\n",
       "         [ 0.51504037],\n",
       "         [ 1.27098527],\n",
       "         [ 0.80191575],\n",
       "         [-0.06472469],\n",
       "         [ 1.29287972],\n",
       "         [ 0.11419973],\n",
       "         [-0.25426624],\n",
       "         [-0.59544197],\n",
       "         [ 0.09722768],\n",
       "         [ 0.12285423],\n",
       "         [-1.76577266],\n",
       "         [ 0.59615703],\n",
       "         [-0.04567468],\n",
       "         [-0.45248632],\n",
       "         [ 0.26081281],\n",
       "         [-0.54454092],\n",
       "         [ 0.2796178 ],\n",
       "         [ 1.20907243],\n",
       "         [-0.1173015 ],\n",
       "         [-1.32392979],\n",
       "         [-0.1038293 ],\n",
       "         [ 0.51759653],\n",
       "         [-1.03622017],\n",
       "         [-1.66251609],\n",
       "         [ 1.47900449],\n",
       "         [-0.69943279],\n",
       "         [-0.64109255],\n",
       "         [ 0.7398149 ],\n",
       "         [-0.41414554],\n",
       "         [ 0.41943243],\n",
       "         [ 0.61528092],\n",
       "         [ 1.48590342],\n",
       "         [ 0.42516107],\n",
       "         [-0.31633421],\n",
       "         [-0.09753108],\n",
       "         [-0.29109951],\n",
       "         [-0.52395856],\n",
       "         [ 0.79690471],\n",
       "         [ 0.39000942],\n",
       "         [-0.62613689]]),\n",
       "  array([[-4.56981243e-01],\n",
       "         [ 3.17890452e-01],\n",
       "         [-5.61526570e-01],\n",
       "         [ 1.28427272e+00],\n",
       "         [ 7.40889233e-01],\n",
       "         [-7.50740051e-01],\n",
       "         [ 1.98062640e+00],\n",
       "         [-5.73027033e-02],\n",
       "         [ 6.45452349e-01],\n",
       "         [-6.38523512e-01],\n",
       "         [-4.00128629e-01],\n",
       "         [ 3.76704609e-01],\n",
       "         [ 6.33776416e-01],\n",
       "         [-1.15206362e-01],\n",
       "         [-2.85166643e-01],\n",
       "         [ 1.34046369e+00],\n",
       "         [-4.60322435e-01],\n",
       "         [-2.64720682e-01],\n",
       "         [ 1.09936385e-01],\n",
       "         [ 3.67229481e-01],\n",
       "         [ 3.30196316e-01],\n",
       "         [ 9.27148643e-01],\n",
       "         [ 8.28091397e-01],\n",
       "         [-4.91506516e-01],\n",
       "         [-2.44675455e+00],\n",
       "         [-9.30276139e-01],\n",
       "         [ 1.15128697e+00],\n",
       "         [ 1.97191663e+00],\n",
       "         [-1.60347613e-01],\n",
       "         [ 8.38801020e-01],\n",
       "         [-1.35961078e+00],\n",
       "         [-1.02296036e+00],\n",
       "         [ 5.62704189e-01],\n",
       "         [ 1.87726658e-01],\n",
       "         [-2.09677485e-01],\n",
       "         [ 1.17785658e+00],\n",
       "         [-1.36053201e-01],\n",
       "         [ 1.42893677e+00],\n",
       "         [ 1.05009276e+00],\n",
       "         [ 9.00854444e-01],\n",
       "         [-3.32650265e-01],\n",
       "         [ 6.95218151e-01],\n",
       "         [-7.57146070e-01],\n",
       "         [ 6.49416239e-01],\n",
       "         [-1.20385297e+00],\n",
       "         [-1.61334147e-01],\n",
       "         [-1.37218950e-01],\n",
       "         [-1.24916590e+00],\n",
       "         [ 5.38187208e-01],\n",
       "         [-8.72264359e-01],\n",
       "         [ 1.74603581e+00],\n",
       "         [-1.54956657e+00],\n",
       "         [ 7.97592855e-01],\n",
       "         [-3.21678152e-01],\n",
       "         [-4.18782239e-01],\n",
       "         [-1.93069330e-01],\n",
       "         [ 9.57241009e-01],\n",
       "         [-9.23812225e-02],\n",
       "         [ 7.56127138e-02],\n",
       "         [-9.33180480e-01],\n",
       "         [ 4.25824108e-01],\n",
       "         [ 5.89453943e-01],\n",
       "         [-2.17511330e+00],\n",
       "         [ 1.05147276e+00],\n",
       "         [-8.12731370e-01],\n",
       "         [-2.93677692e-01],\n",
       "         [-7.46876279e-01],\n",
       "         [-6.79044266e-01],\n",
       "         [-2.67923295e-01],\n",
       "         [ 2.21142109e-01],\n",
       "         [ 4.10390347e-01],\n",
       "         [-1.05950645e+00],\n",
       "         [-2.83682300e-01],\n",
       "         [-1.72655966e-01],\n",
       "         [-3.03355678e-01],\n",
       "         [ 9.98543924e-01],\n",
       "         [-8.85825760e-01],\n",
       "         [-1.50644680e+00],\n",
       "         [-6.28578145e-01],\n",
       "         [-1.22479074e-01],\n",
       "         [-1.60879974e+00],\n",
       "         [ 8.55081516e-04],\n",
       "         [-6.64350102e-01],\n",
       "         [ 1.92311826e+00],\n",
       "         [-6.29601997e-01],\n",
       "         [-3.16071107e-01],\n",
       "         [-7.54109595e-01],\n",
       "         [-8.70576094e-02],\n",
       "         [ 1.15594609e+00],\n",
       "         [ 1.49140268e+00],\n",
       "         [ 4.27459120e-01],\n",
       "         [-6.93835428e-01],\n",
       "         [-2.01306665e-01],\n",
       "         [-4.37340632e-01],\n",
       "         [ 3.27725848e-01],\n",
       "         [ 6.69592943e-01],\n",
       "         [ 5.29658319e-01],\n",
       "         [-4.63363750e-01],\n",
       "         [ 2.82934305e-01],\n",
       "         [ 1.37574365e+00]]),\n",
       "  array([[ 0.23902516],\n",
       "         [-2.06655031],\n",
       "         [-0.88889737],\n",
       "         [-1.01779335],\n",
       "         [-0.05889148],\n",
       "         [-1.54707851],\n",
       "         [-0.78765115],\n",
       "         [ 0.93938273],\n",
       "         [ 0.76025869],\n",
       "         [-0.04980098],\n",
       "         [-0.15153574],\n",
       "         [ 0.45110508],\n",
       "         [ 0.489171  ],\n",
       "         [ 0.12433346],\n",
       "         [ 1.01958562],\n",
       "         [ 1.87722649],\n",
       "         [-0.25930522],\n",
       "         [-0.80791607],\n",
       "         [-1.13863316],\n",
       "         [ 1.60190944],\n",
       "         [ 0.67727923],\n",
       "         [ 0.3447736 ],\n",
       "         [-1.17600804],\n",
       "         [-0.7657682 ],\n",
       "         [-0.35785312],\n",
       "         [-0.3289854 ],\n",
       "         [ 0.79318571],\n",
       "         [ 0.53039919],\n",
       "         [ 0.02567085],\n",
       "         [-0.90825001],\n",
       "         [-0.89617241],\n",
       "         [-1.98747977],\n",
       "         [ 0.1737974 ],\n",
       "         [-1.26757513],\n",
       "         [-1.14613987],\n",
       "         [-0.57247031],\n",
       "         [ 1.04688765],\n",
       "         [-0.15985143],\n",
       "         [-1.21020031],\n",
       "         [ 0.17233039],\n",
       "         [-1.13978445],\n",
       "         [-0.25787705],\n",
       "         [ 0.78863455],\n",
       "         [ 0.65699901],\n",
       "         [-0.6231307 ],\n",
       "         [-0.31728978],\n",
       "         [ 1.84444058],\n",
       "         [ 0.0328804 ],\n",
       "         [ 0.22041111],\n",
       "         [ 2.17731135],\n",
       "         [ 0.23521273],\n",
       "         [-1.13322048],\n",
       "         [-2.12328121],\n",
       "         [ 0.66175089],\n",
       "         [-0.67501584],\n",
       "         [ 0.38283345],\n",
       "         [-2.55717215],\n",
       "         [-0.50122999],\n",
       "         [ 0.38871359],\n",
       "         [-0.37382956],\n",
       "         [-1.58493191],\n",
       "         [ 0.01378631],\n",
       "         [-0.25263422],\n",
       "         [-2.52367236],\n",
       "         [-0.81671624],\n",
       "         [-1.0798559 ],\n",
       "         [ 3.15893988],\n",
       "         [ 0.97760535],\n",
       "         [ 0.04155333],\n",
       "         [-0.11641504],\n",
       "         [ 2.32115896],\n",
       "         [ 0.04141197],\n",
       "         [ 0.23235389],\n",
       "         [ 0.42870721],\n",
       "         [-1.55545008],\n",
       "         [-1.39606418],\n",
       "         [ 0.49889428],\n",
       "         [ 1.1466418 ],\n",
       "         [-0.63284338],\n",
       "         [ 1.12548132],\n",
       "         [ 0.62754986],\n",
       "         [ 0.3930872 ],\n",
       "         [ 0.96551218],\n",
       "         [-0.73159743],\n",
       "         [-0.17363302],\n",
       "         [-0.83365165],\n",
       "         [ 1.54791221],\n",
       "         [-0.22813981],\n",
       "         [ 0.41062999],\n",
       "         [ 0.14189081],\n",
       "         [-0.74522316],\n",
       "         [ 1.95583694],\n",
       "         [-0.88209043],\n",
       "         [-0.9543097 ],\n",
       "         [-2.34229707],\n",
       "         [-0.35328837],\n",
       "         [ 0.90040563],\n",
       "         [-1.18111009],\n",
       "         [ 1.75877724],\n",
       "         [-1.79050723]]),\n",
       "  array([[ 0.41009553],\n",
       "         [ 0.65661201],\n",
       "         [ 0.82906501],\n",
       "         [ 1.40763236],\n",
       "         [ 1.68575302],\n",
       "         [ 1.90019828],\n",
       "         [ 1.50130716],\n",
       "         [ 0.42677917],\n",
       "         [ 0.08407905],\n",
       "         [-0.58317699],\n",
       "         [ 0.72797788],\n",
       "         [ 0.51811086],\n",
       "         [ 0.34936069],\n",
       "         [-0.28702608],\n",
       "         [-0.34114435],\n",
       "         [ 0.66626643],\n",
       "         [-0.59993121],\n",
       "         [ 1.0458478 ],\n",
       "         [-0.74217428],\n",
       "         [-0.25640819],\n",
       "         [-0.98348139],\n",
       "         [-0.01918955],\n",
       "         [-0.5271948 ],\n",
       "         [-0.81016404],\n",
       "         [ 0.0452335 ],\n",
       "         [ 0.06058392],\n",
       "         [ 0.32285706],\n",
       "         [ 2.44625121],\n",
       "         [ 0.27625711],\n",
       "         [-0.8949271 ],\n",
       "         [ 0.6533699 ],\n",
       "         [-0.9626563 ],\n",
       "         [-0.69904091],\n",
       "         [-1.5733677 ],\n",
       "         [ 1.03120084],\n",
       "         [ 0.70325609],\n",
       "         [-1.30398389],\n",
       "         [ 0.97996661],\n",
       "         [-0.08399404],\n",
       "         [-0.73721976],\n",
       "         [-0.91337703],\n",
       "         [-0.46626297],\n",
       "         [-2.08878277],\n",
       "         [-1.06999861],\n",
       "         [ 1.45278596],\n",
       "         [ 0.01744915],\n",
       "         [ 1.09245393],\n",
       "         [ 1.1705789 ],\n",
       "         [ 1.2991339 ],\n",
       "         [ 0.65986729],\n",
       "         [ 0.24944939],\n",
       "         [ 1.57472658],\n",
       "         [-0.61272394],\n",
       "         [ 0.94623994],\n",
       "         [ 1.32426995],\n",
       "         [ 0.53094102],\n",
       "         [ 0.12936318],\n",
       "         [ 2.0692003 ],\n",
       "         [ 0.18376249],\n",
       "         [ 0.31234561],\n",
       "         [ 1.14256508],\n",
       "         [-0.20619297],\n",
       "         [ 0.40874705],\n",
       "         [-1.4583783 ],\n",
       "         [ 2.3194342 ],\n",
       "         [-0.53166476],\n",
       "         [ 0.46756403],\n",
       "         [-0.0354047 ],\n",
       "         [ 0.58062228],\n",
       "         [-0.96490128],\n",
       "         [-0.69561249],\n",
       "         [-1.64555433],\n",
       "         [-0.39084001],\n",
       "         [ 0.79326442],\n",
       "         [ 0.84881047],\n",
       "         [ 1.24641835],\n",
       "         [ 1.32022886],\n",
       "         [ 1.1990287 ],\n",
       "         [ 1.3495127 ],\n",
       "         [ 0.1600217 ],\n",
       "         [-1.1516854 ],\n",
       "         [ 0.24762857],\n",
       "         [-0.52530416],\n",
       "         [ 1.5847626 ],\n",
       "         [ 1.81493799],\n",
       "         [-0.97573352],\n",
       "         [-1.12140188],\n",
       "         [ 0.17046383],\n",
       "         [-0.70784579],\n",
       "         [ 2.70049872],\n",
       "         [-0.78655539],\n",
       "         [ 0.70923606],\n",
       "         [ 0.589149  ],\n",
       "         [-1.24061331],\n",
       "         [ 1.6095095 ],\n",
       "         [ 0.55089354],\n",
       "         [ 0.1340689 ],\n",
       "         [-0.7815621 ],\n",
       "         [-0.64662438],\n",
       "         [ 0.59003544]]),\n",
       "  array([[-0.95510402],\n",
       "         [-0.7501893 ],\n",
       "         [-1.30904221],\n",
       "         [-1.45303165],\n",
       "         [ 1.859893  ],\n",
       "         [-1.75643527],\n",
       "         [-0.75098129],\n",
       "         [ 0.2045661 ],\n",
       "         [ 1.82347494],\n",
       "         [-0.86921165],\n",
       "         [ 0.33566133],\n",
       "         [ 0.96311411],\n",
       "         [ 2.71752153],\n",
       "         [-0.14483515],\n",
       "         [-0.07868606],\n",
       "         [ 0.3410726 ],\n",
       "         [ 0.74537205],\n",
       "         [-0.85174666],\n",
       "         [-0.21503469],\n",
       "         [ 1.02748579],\n",
       "         [ 1.15485137],\n",
       "         [ 1.77850846],\n",
       "         [-0.7182567 ],\n",
       "         [ 1.40135816],\n",
       "         [ 0.0327255 ],\n",
       "         [ 0.14082329],\n",
       "         [-0.31812457],\n",
       "         [-0.60853885],\n",
       "         [-0.82004195],\n",
       "         [-0.82438775],\n",
       "         [ 0.30190378],\n",
       "         [ 0.88306855],\n",
       "         [-0.03867085],\n",
       "         [-0.29563188],\n",
       "         [-0.80653196],\n",
       "         [-0.46535698],\n",
       "         [-1.68369018],\n",
       "         [-1.16467296],\n",
       "         [-1.43844848],\n",
       "         [-1.17816577],\n",
       "         [ 0.81863136],\n",
       "         [-1.30938285],\n",
       "         [ 0.48594018],\n",
       "         [-0.94196094],\n",
       "         [ 1.44111633],\n",
       "         [ 0.07159135],\n",
       "         [ 1.9203762 ],\n",
       "         [ 0.5238266 ],\n",
       "         [-0.91637173],\n",
       "         [ 0.10496755],\n",
       "         [ 0.75889092],\n",
       "         [ 1.70290229],\n",
       "         [-0.95072371],\n",
       "         [ 0.63307788],\n",
       "         [-1.04663777],\n",
       "         [-0.39147859],\n",
       "         [ 0.56161496],\n",
       "         [ 0.01067193],\n",
       "         [ 0.28929934],\n",
       "         [ 0.97035728],\n",
       "         [ 0.50417315],\n",
       "         [ 0.05633348],\n",
       "         [-1.16996806],\n",
       "         [-0.72383134],\n",
       "         [ 0.64727562],\n",
       "         [-0.26333455],\n",
       "         [ 0.64469019],\n",
       "         [-1.527679  ],\n",
       "         [ 1.36293418],\n",
       "         [-0.07999526],\n",
       "         [-0.63963828],\n",
       "         [-2.87358874],\n",
       "         [-0.35266141],\n",
       "         [ 0.32301575],\n",
       "         [ 0.86302864],\n",
       "         [ 0.87802878],\n",
       "         [ 1.6967897 ],\n",
       "         [ 0.72688428],\n",
       "         [-1.57061686],\n",
       "         [-0.77750664],\n",
       "         [ 0.38485629],\n",
       "         [ 1.10818866],\n",
       "         [ 2.46007644],\n",
       "         [ 0.81227445],\n",
       "         [ 0.48065416],\n",
       "         [ 1.06644155],\n",
       "         [ 0.08787773],\n",
       "         [-0.54663461],\n",
       "         [-1.86584548],\n",
       "         [ 0.59848112],\n",
       "         [ 0.31101189],\n",
       "         [-0.22426979],\n",
       "         [ 0.02541422],\n",
       "         [-0.91230605],\n",
       "         [ 0.71588261],\n",
       "         [ 0.03612157],\n",
       "         [-0.70837822],\n",
       "         [ 0.89678693],\n",
       "         [-1.43002316],\n",
       "         [ 0.00626616]])],\n",
       " (100, 1),\n",
       " 5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings, embeddings[0].shape, len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOneHot(idx): #One-hot based on library size\n",
    "    one_hot = np.zeros((vocabSize,1))\n",
    "    one_hot[idx] = 1 \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print(getOneHot(2)) #one hot vector of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets make out weights and biases\n",
    "numUnits = 50\n",
    "h0 = torch.tensor(np.zeros((numUnits,1)))\n",
    "Wh = torch.tensor(np.random.uniform(0,1,(numUnits,numUnits)),requires_grad=True)\n",
    "Wx = torch.tensor(np.random.uniform(0,1,(numUnits,numFeatures)),requires_grad=True)\n",
    "Wy = torch.tensor(np.random.uniform(0,1,(vocabSize,numUnits)),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 50]) torch.Size([50, 100]) torch.Size([80, 50]) torch.Size([50, 1])\n"
     ]
    }
   ],
   "source": [
    "print(Wh.shape,Wx.shape,Wy.shape,h0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Forward Pass based on a single timestep\n",
    "def stepForward(xt,Wx,Wh,Wy,prevMemory):\n",
    "    x_frd = torch.matmul(Wx,torch.from_numpy(xt)) #Wx*X(t)\n",
    "    h_frd = torch.matmul(Wh,prevMemory)\n",
    "    ht = torch.tanh(x_frd+h_frd) #Flowing Activation\n",
    "    yt_hat = F.softmax(torch.matmul(Wy,ht), dim = 0)\n",
    "    return ht, yt_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht, yt_hat = stepForward(embeddings[0],Wx,Wh,Wy,h0) #single input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([80, 1]), tensor(1., dtype=torch.float64, grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt_hat.shape , yt_hat.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullForwardRNN(X,Wx,Wh,Wy,prevMemory):#Unrolling of network\n",
    "    y_hat = []\n",
    "    for t in range(len(X)): #List of embeddings\n",
    "        ht, yt_hat = stepForward(X[t],Wx,Wh,Wy,prevMemory)\n",
    "        prevMemory = ht\n",
    "        y_hat.append(yt_hat)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = fullForwardRNN(embeddings,Wx,Wh,Wy,h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeLoss(y,y_hat):\n",
    "    loss = 0\n",
    "    for yi,yi_hat in zip(y,y_hat):\n",
    "        Li = -torch.log2(yi_hat[yi==1]) #Crossentropy Loss\n",
    "        loss += Li\n",
    "    return loss/len(y) #avg loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for idx in outputString:\n",
    "    y.append(getOneHot(idx)) #Onehot the labels to compare to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8.0380], dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(computeLoss(y,y_hat)) #Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateParams(Wx,Wh,Wy,dWx,dWh,dWy,lr):\n",
    "    with torch.no_grad(): #Does not affect gradient information\n",
    "        Wx -= lr*dWx\n",
    "        Wh -= lr*dWh\n",
    "        Wy -= lr*dWy\n",
    "    return Wx,Wh,Wy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Function\n",
    "def trainRNN(X,y,Wx,Wh,Wy,prevMemory,lr,nepoch):\n",
    "    losses = []\n",
    "    for epoch in range(nepoch):\n",
    "        y_hat = fullForwardRNN(embeddings,Wx,Wh,Wy,prevMemory)\n",
    "        loss = computeLoss(y,y_hat)\n",
    "        loss.backward() #Compute gradient for all the parameters wrt Loss\n",
    "        losses.append(loss)\n",
    "        print(\"Loss after epoch =%d: %f\" %(epoch,loss))\n",
    "        sys.stdout.flush() \n",
    "        dWx = Wx.grad.data\n",
    "        dWh = Wh.grad.data\n",
    "        dWy = Wy.grad.data\n",
    "        Wx,Wh,Wy = updateParams(Wx,Wh,Wy,dWx,dWh,dWy,lr)\n",
    "        Wx.grad.data.zero_() #Good to reset Gradient for nect compute\n",
    "        Wh.grad.data.zero_()\n",
    "        Wy.grad.data.zero_()\n",
    "    return Wx,Wh,Wy,losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch =0: 8.037961\n",
      "Loss after epoch =1: 8.006729\n",
      "Loss after epoch =2: 7.975593\n",
      "Loss after epoch =3: 7.944553\n",
      "Loss after epoch =4: 7.913609\n",
      "Loss after epoch =5: 7.882759\n",
      "Loss after epoch =6: 7.852004\n",
      "Loss after epoch =7: 7.821344\n",
      "Loss after epoch =8: 7.790778\n",
      "Loss after epoch =9: 7.760307\n",
      "Loss after epoch =10: 7.729930\n",
      "Loss after epoch =11: 7.699647\n",
      "Loss after epoch =12: 7.669459\n",
      "Loss after epoch =13: 7.639366\n",
      "Loss after epoch =14: 7.609367\n",
      "Loss after epoch =15: 7.579464\n",
      "Loss after epoch =16: 7.549655\n",
      "Loss after epoch =17: 7.519942\n",
      "Loss after epoch =18: 7.490324\n",
      "Loss after epoch =19: 7.460803\n",
      "Loss after epoch =20: 7.431378\n",
      "Loss after epoch =21: 7.402049\n",
      "Loss after epoch =22: 7.372817\n",
      "Loss after epoch =23: 7.343682\n",
      "Loss after epoch =24: 7.314645\n",
      "Loss after epoch =25: 7.285706\n",
      "Loss after epoch =26: 7.256865\n",
      "Loss after epoch =27: 7.228123\n",
      "Loss after epoch =28: 7.199480\n",
      "Loss after epoch =29: 7.170937\n",
      "Loss after epoch =30: 7.142493\n",
      "Loss after epoch =31: 7.114150\n",
      "Loss after epoch =32: 7.085907\n",
      "Loss after epoch =33: 7.057765\n",
      "Loss after epoch =34: 7.029725\n",
      "Loss after epoch =35: 7.001787\n",
      "Loss after epoch =36: 6.973950\n",
      "Loss after epoch =37: 6.946216\n",
      "Loss after epoch =38: 6.918585\n",
      "Loss after epoch =39: 6.891057\n",
      "Loss after epoch =40: 6.863633\n",
      "Loss after epoch =41: 6.836312\n",
      "Loss after epoch =42: 6.809095\n",
      "Loss after epoch =43: 6.781983\n",
      "Loss after epoch =44: 6.754976\n",
      "Loss after epoch =45: 6.728073\n",
      "Loss after epoch =46: 6.701276\n",
      "Loss after epoch =47: 6.674584\n",
      "Loss after epoch =48: 6.647998\n",
      "Loss after epoch =49: 6.621518\n",
      "Loss after epoch =50: 6.595144\n",
      "Loss after epoch =51: 6.568877\n",
      "Loss after epoch =52: 6.542716\n",
      "Loss after epoch =53: 6.516663\n",
      "Loss after epoch =54: 6.490716\n",
      "Loss after epoch =55: 6.464876\n",
      "Loss after epoch =56: 6.439145\n",
      "Loss after epoch =57: 6.413520\n",
      "Loss after epoch =58: 6.388004\n",
      "Loss after epoch =59: 6.362595\n",
      "Loss after epoch =60: 6.337294\n",
      "Loss after epoch =61: 6.312102\n",
      "Loss after epoch =62: 6.287018\n",
      "Loss after epoch =63: 6.262042\n",
      "Loss after epoch =64: 6.237176\n",
      "Loss after epoch =65: 6.212417\n",
      "Loss after epoch =66: 6.187768\n",
      "Loss after epoch =67: 6.163228\n",
      "Loss after epoch =68: 6.138796\n",
      "Loss after epoch =69: 6.114474\n",
      "Loss after epoch =70: 6.090261\n",
      "Loss after epoch =71: 6.066157\n",
      "Loss after epoch =72: 6.042163\n",
      "Loss after epoch =73: 6.018278\n",
      "Loss after epoch =74: 5.994503\n",
      "Loss after epoch =75: 5.970837\n",
      "Loss after epoch =76: 5.947281\n",
      "Loss after epoch =77: 5.923834\n",
      "Loss after epoch =78: 5.900497\n",
      "Loss after epoch =79: 5.877270\n",
      "Loss after epoch =80: 5.854153\n",
      "Loss after epoch =81: 5.831145\n",
      "Loss after epoch =82: 5.808248\n",
      "Loss after epoch =83: 5.785460\n",
      "Loss after epoch =84: 5.762781\n",
      "Loss after epoch =85: 5.740213\n",
      "Loss after epoch =86: 5.717754\n",
      "Loss after epoch =87: 5.695405\n",
      "Loss after epoch =88: 5.673166\n",
      "Loss after epoch =89: 5.651037\n",
      "Loss after epoch =90: 5.629017\n",
      "Loss after epoch =91: 5.607107\n",
      "Loss after epoch =92: 5.585306\n",
      "Loss after epoch =93: 5.563615\n",
      "Loss after epoch =94: 5.542033\n",
      "Loss after epoch =95: 5.520561\n",
      "Loss after epoch =96: 5.499198\n",
      "Loss after epoch =97: 5.477943\n",
      "Loss after epoch =98: 5.456798\n",
      "Loss after epoch =99: 5.435762\n"
     ]
    }
   ],
   "source": [
    "Wx,Wh,Wy,losses = trainRNN(embeddings,y,Wx,Wh,Wy,h0,0.001,100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
