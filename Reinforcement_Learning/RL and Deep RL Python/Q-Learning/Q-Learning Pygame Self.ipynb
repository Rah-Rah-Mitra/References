{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment class keeping track of all actions/positions\n",
    "class Field:\n",
    "    def __init__(self, size, item_pickup, item_dropoff, start_position):\n",
    "        self.size = size #grid size\n",
    "        self.item_pickup = item_pickup #item pickup coardinate\n",
    "        self.item_dropoff = item_dropoff #item dropoff coardinate\n",
    "        self.position = start_position #agent position at start when init\n",
    "        self.item_in_car = False\n",
    "\n",
    "    def get_number_of_states(self):\n",
    "        return self.size**4 * 2 #no. of states: \n",
    "                                    #item_pickup 10*10 locations\n",
    "                                    #item_dropoff 10*10 locations \n",
    "                                    #item_in_car 2 possibilites\n",
    "\n",
    "    def get_state(self): #assigning the state it y-axis value in q-table (20000)\n",
    "        state = self.position[0] * self.size**3 * 2          #lets say player position is at (9,0) and item at (0,0) \n",
    "        state = state + self.position[1] * self.size**2 * 2  #we are taking all the possibilities and numbering the states\n",
    "        state = state + self.item_pickup[0] * self.size * 2  #and assigning the state value with respect to player pos\n",
    "        state = state + self.item_pickup[1] * 2\n",
    "\n",
    "        if self.item_in_car:\n",
    "            state = state + 1\n",
    "        return state\n",
    "\n",
    "    def make_action(self,action):\n",
    "        (x,y)= self.position\n",
    "        if action == 0:   # down\n",
    "            if y == self.size -1:\n",
    "                return -10, False #Reward,Reached Goal\n",
    "            else: \n",
    "                self.position = (x, y+1)\n",
    "                return -1, False\n",
    "            \n",
    "        elif action == 1: # up\n",
    "            if y == 0:\n",
    "                return -10, False #Reward,Reached Goal\n",
    "            else: \n",
    "                self.position = (x, y-1)\n",
    "                return -1, False\n",
    "            \n",
    "        elif action == 2: # left\n",
    "            if x == 0:\n",
    "                return -10, False #Reward,Reached Goal\n",
    "            else: \n",
    "                self.position = (x-1, y)\n",
    "                return -1, False\n",
    "            \n",
    "        elif action == 3: # right\n",
    "            if x == self.size -1:\n",
    "                return -10, False #Reward,Reached Goal\n",
    "            else: \n",
    "                self.position = (x+1, y)\n",
    "                return -1, False\n",
    "            \n",
    "        elif action == 4: # pickup\n",
    "            if self.item_in_car: #item already in car\n",
    "                return -10, False\n",
    "            elif self.item_pickup != (x,y): #item not at current position\n",
    "                return -10, False\n",
    "            else:\n",
    "                self.item_in_car = True #item at playerpos and item not in car\n",
    "                return +20, False\n",
    "            \n",
    "        elif action == 5: # dropoff\n",
    "            if not self.item_in_car: #item not in car and try to dropoff\n",
    "                return -10, False\n",
    "            elif self.item_dropoff != (x,y): #item in car but drop off wrong location\n",
    "                self.item_pickup = (x,y)\n",
    "                self.item_in_car = False\n",
    "                return -10, False\n",
    "            else: #item in  car and correct dropoff location\n",
    "                self.item_in_car = False\n",
    "                return 20, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Learning Algo\n",
    "size = 10\n",
    "item_pickup = (0,0)\n",
    "item_dropoff = (9,9)\n",
    "start_position = (9,0)\n",
    "\n",
    "field = Field(size=size,item_pickup=item_pickup,item_dropoff=item_dropoff,start_position=start_position)\n",
    "\n",
    "number_of_states = field.get_number_of_states()\n",
    "number_of_actions = 6 #0-5\n",
    "\n",
    "q_table = np.zeros((number_of_states,number_of_actions))\n",
    "\n",
    "#Hyperparameters, dont worry about them now\n",
    "epsilon = 0.1\n",
    "alpha = 0.1\n",
    "gamma = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QL_solution():\n",
    "    field = Field(size=size,item_pickup=item_pickup,item_dropoff=item_dropoff,start_position=start_position)\n",
    "    \n",
    "    epsilon = 0.1\n",
    "    alpha = 0.1\n",
    "    gamma = 0.6\n",
    "    \n",
    "    done = False\n",
    "    steps = 0\n",
    "    \n",
    "    while not done:\n",
    "        state = field.get_state()\n",
    "        if random.uniform(0,1) < epsilon:\n",
    "            action = random.randint(0,5) #Explore\n",
    "        else:\n",
    "            action = np.argmax(q_table[state]) #Exploit\n",
    "        # print (action) #Check action made\n",
    "        reward, done = field.make_action(action)\n",
    "        \n",
    "        new_state = field.get_state()\n",
    "        new_state_max = np.max(q_table[new_state])\n",
    "        \n",
    "        q_table[state, action] = (1-alpha)*q_table[state, action]+alpha*(reward+gamma*new_state_max - q_table[state, action])\n",
    "                        \n",
    "        steps = steps +1\n",
    "        \n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.44567"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run= [QL_solution() for _ in range(100000)]\n",
    "sum(run)/len(run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QL_solution()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
