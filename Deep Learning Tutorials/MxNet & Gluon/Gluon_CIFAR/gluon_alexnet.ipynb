{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for an alternate implementation -- AlexNet in Gluon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import nd, autograd, gluon\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outputs = 10 # 10 output digits\n",
    "batch_size = 128 # mini batch\n",
    "epochs = 10 # total training loops\n",
    "learning_rate = 0.01 # amount we update parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR images are available via a dataset. This is a little different than Keras, in that you pass the transformer as a function to normalize, and the data contains input images and output labels. The advantage of this structure shows in very large data sets, where the transformation is done on demand, letting you start your model running sooner, incrementally normalizing one batch at a time.\n",
    "\n",
    "This is integer style pixel data, so we'll need to normalize it on 0-1.\n",
    "\n",
    "OK -- here is an odd one. Keras convolutions are in image order (x, y, channels). Gluon convolutions are un a unique order to Gluon (channels, x, y). So we need to move the 0, 1, 2 axes of the source image to 2, 0, 1 with transpose.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data, label):\n",
    "    data = mx.nd.transpose(data, (2,0,1))\n",
    "    data = data.astype(np.float32) / 255.0\n",
    "    return data, label\n",
    "train_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.CIFAR10(train=True, transform=transform),\n",
    "                                      batch_size, shuffle=True)\n",
    "test_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.CIFAR10(train=False, transform=transform),\n",
    "                                     batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do the same kind of definition with Gluon as with Keras -- adding layers inside of loops. These parameters will control the layer definitions.\n",
    "\n",
    "One thing to notice, MxNet  -- the input size can be computed for us automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = [11, 5, 3, 3, 3]\n",
    "filters = [96, 192, 384, 384, 256]\n",
    "pooling = [3, 3, 0, 0, 3]\n",
    "strides = [2, 2, 0, 0, 2]\n",
    "dense_units = [4096, 4096]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, you don't have a final softmax *layer*, MxNet handles he softmax inside this loss function, so the output is a straight linear mapping -- no activation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = gluon.nn.HybridSequential()\n",
    "with alexnet.name_scope():\n",
    "    for kernel, filter, pool, stride in zip(kernels, filters, pooling, strides):\n",
    "        \n",
    "        alexnet.add(gluon.nn.Conv2D(channels=filter, \n",
    "                                    kernel_size=kernel,\n",
    "                                    padding=(kernel//2),\n",
    "                                    activation='relu'))\n",
    "        if pool:\n",
    "            alexnet.add(gluon.nn.MaxPool2D(pool_size=pool, \n",
    "                                           strides=stride))\n",
    "    alexnet.add(gluon.nn.Flatten())\n",
    "    for units in dense_units:\n",
    "        alexnet.add(gluon.nn.Dense(units, activation='relu'))\n",
    "    alexnet.add(gluon.nn.Dense(num_outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gluon requires a context, either `cpu` or `gpu`. You can change this to `cpu` if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gluon requires that parameters be explicitly initialied. Here we are using the Xavier initializer, which is a sensible default.\n",
    "\n",
    "You must initialize before you can set up a trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.collect_params().initialize(mx.init.Xavier(), ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let't take a look at the resulting network. We need to feed in a sample batch to infer the network size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "        Layer (type)                                Output Shape         Param #\n",
      "================================================================================\n",
      "               Input                            (128, 3, 32, 32)               0\n",
      "        Activation-1   <Symbol hybridsequential0_conv0_relu_fwd>               0\n",
      "        Activation-2                           (128, 96, 32, 32)               0\n",
      "            Conv2D-3                           (128, 96, 32, 32)           34944\n",
      "         MaxPool2D-4                           (128, 96, 15, 15)               0\n",
      "        Activation-5   <Symbol hybridsequential0_conv1_relu_fwd>               0\n",
      "        Activation-6                          (128, 192, 15, 15)               0\n",
      "            Conv2D-7                          (128, 192, 15, 15)          460992\n",
      "         MaxPool2D-8                            (128, 192, 7, 7)               0\n",
      "        Activation-9   <Symbol hybridsequential0_conv2_relu_fwd>               0\n",
      "       Activation-10                            (128, 384, 7, 7)               0\n",
      "           Conv2D-11                            (128, 384, 7, 7)          663936\n",
      "       Activation-12   <Symbol hybridsequential0_conv3_relu_fwd>               0\n",
      "       Activation-13                            (128, 384, 7, 7)               0\n",
      "           Conv2D-14                            (128, 384, 7, 7)         1327488\n",
      "       Activation-15   <Symbol hybridsequential0_conv4_relu_fwd>               0\n",
      "       Activation-16                            (128, 256, 7, 7)               0\n",
      "           Conv2D-17                            (128, 256, 7, 7)          884992\n",
      "        MaxPool2D-18                            (128, 256, 3, 3)               0\n",
      "          Flatten-19                                 (128, 2304)               0\n",
      "       Activation-20  <Symbol hybridsequential0_dense0_relu_fwd>               0\n",
      "       Activation-21                                 (128, 4096)               0\n",
      "            Dense-22                                 (128, 4096)         9441280\n",
      "       Activation-23  <Symbol hybridsequential0_dense1_relu_fwd>               0\n",
      "       Activation-24                                 (128, 4096)               0\n",
      "            Dense-25                                 (128, 4096)        16781312\n",
      "            Dense-26                                   (128, 10)           40970\n",
      "================================================================================\n",
      "Parameters in forward computation graph, duplicate included\n",
      "   Total params: 29635914\n",
      "   Trainable params: 29635914\n",
      "   Non-trainable params: 0\n",
      "Shared params in forward computation graph: 0\n",
      "Unique parameters in model: 29635914\n",
      "--------------------------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for i, (d, l) in enumerate(train_data):\n",
    "    print(alexnet.summary(d.as_in_context(ctx)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you network doesn't change shape, you can `hybridize` it, which makes Gluon run in a precomplied mode much like Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.hybridize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as always, learning is done with an optimizer and a loss function, learning a classifier with categorical cross entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(alexnet.collect_params(), 'sgd', {'learning_rate': learning_rate})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where Gluon isn't as convenient as Keras -- defining your own accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iterator, net):\n",
    "    acc = mx.metric.Accuracy()\n",
    "    for i, (data, label) in enumerate(data_iterator):\n",
    "        data = data.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "        output = net(data)\n",
    "        predictions = nd.argmax(output, axis=1)\n",
    "        acc.update(preds=predictions, labels=label)\n",
    "    return acc.get()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the training loop. Again this isn't as declarative as Keras. It does give you options for more control on comple models however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 2.185494102490571, Train_acc 0.25844, Test_acc 0.2624, Time 18.001178\n",
      "Epoch 1. Loss: 1.9511077665971492, Train_acc 0.29912, Test_acc 0.298, Time 17.876366\n",
      "Epoch 2. Loss: 1.8041707043952524, Train_acc 0.3426, Test_acc 0.3507, Time 16.271401\n",
      "Epoch 3. Loss: 1.6796391537803523, Train_acc 0.38888, Test_acc 0.3875, Time 16.748858\n",
      "Epoch 4. Loss: 1.5860475260924667, Train_acc 0.41488, Test_acc 0.4174, Time 17.383099\n",
      "Epoch 5. Loss: 1.4999414477380506, Train_acc 0.45064, Test_acc 0.4543, Time 17.039613\n",
      "Epoch 6. Loss: 1.4375727949410486, Train_acc 0.47632, Test_acc 0.4715, Time 17.369838\n",
      "Epoch 7. Loss: 1.3887894382178314, Train_acc 0.52838, Test_acc 0.5201, Time 17.375701\n",
      "Epoch 8. Loss: 1.3344149353245434, Train_acc 0.51844, Test_acc 0.5071, Time 18.395933\n",
      "Epoch 9. Loss: 1.2801594779672918, Train_acc 0.5269, Test_acc 0.5148, Time 17.811769\n"
     ]
    }
   ],
   "source": [
    "smoothing_constant = .01\n",
    "moving_loss = 0.0\n",
    "\n",
    "for e in range(epochs):\n",
    "    start = time()\n",
    "    for i, (d, l) in enumerate(train_data):\n",
    "        data = d.as_in_context(ctx)\n",
    "        label = l.as_in_context(ctx)\n",
    "        with autograd.record():\n",
    "            output = alexnet(data)\n",
    "            loss = softmax_cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        trainer.step(data.shape[0])\n",
    "\n",
    "        #  Keep a moving average of the losses\n",
    "        curr_loss = nd.mean(loss).asscalar()\n",
    "        moving_loss = (curr_loss if ((i == 0) and (e == 0))\n",
    "                       else (1 - smoothing_constant) * moving_loss + (smoothing_constant) * curr_loss)\n",
    "    elapsed = time() - start\n",
    "\n",
    "    test_accuracy = evaluate_accuracy(test_data, alexnet)\n",
    "    train_accuracy = evaluate_accuracy(train_data, alexnet)\n",
    "    print(\"Epoch %s. Loss: %s, Train_acc %s, Test_acc %s, Time %f\" % (e, moving_loss, train_accuracy, test_accuracy, elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not shockingly different than the Keras implementation, but in my opinion, less convenient for this type of model. The hand rolled training loops can be a benefit when you need logic inside you model. You can very much mix in rules and computation -- `if` statements and the like -- for very sophisticated production models.\n",
    "\n",
    "Little things, like the lack of the built in progress bar are not a big deal, but a missing bit of usability compared to Keras as well. Overall -- an interesting set of tradeoffs, size inference, which cures the problems you'll run into with Keras most commonly building models, but much more code to run the actual training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
