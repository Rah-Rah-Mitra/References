{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as a project, we'll experiment with recurrent networks and learn a *language model*. A language model is simply a network that predicts the next word or character when trained on a set of data. \n",
    "\n",
    "We'll train James Joyce' *Ulysses*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import LSTM, BatchNormalization, CuDNNLSTM, Dense, Dropout, Embedding, Reshape\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've downloaded the text from Project Gutenberg, which is a great source of free texts of classic works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ulysses.txt\", 'r', encoding='utf8') as f:\n",
    "    text_content = f.read().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we cannot exactly use text as is, we need to turn it into numbers. To do this, we'll use the `Tokenizer` to generate word to number mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text_content])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a list of numbers rather than a string of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13931, 1, 293, 292, 2236, 2, 2447, 22, 827, 5448]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinals = tokenizer.texts_to_sequences([text_content])[0]\n",
    "ordinals[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm -- how many unique words did we find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK -- working with sequences, we need something to predict. That will be -- the next word. So, for any given sequence of a given length, the next word from the source text will be the output. This means we'll be taking out one hot array and chopping it into sequences for input, and single words as output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 32\n",
    "# make sure we don't go past the end of the sequence or ordinals\n",
    "chunks = len(ordinals) - sequence_length\n",
    "# sequence numbers for context words\n",
    "inputs = np.zeros((chunks, sequence_length), dtype=np.int32)\n",
    "# one hot encodings for target words\n",
    "outputs = np.zeros((chunks, unique_tokens), dtype=np.float)\n",
    "for i in range(0, chunks):\n",
    "    # copy in the ordinal word numbers for a sequence or words\n",
    "    context = np.array(ordinals[i:i+sequence_length], dtype=np.int32)\n",
    "    inputs[i] = context\n",
    "    #one hot flags the single word\n",
    "    target = ordinals[i+sequence_length]\n",
    "    outputs[i, target] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each string will need to be in a matrix, and formulated as a 'batch'. We'll space pre-pad, and trim as needed to make sure we are the correct sequence length for our model.\n",
    "\n",
    "These encoding and decoding functions will turn our model into usable text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_string(s, max_len=sequence_length):\n",
    "    # only to max length\n",
    "    ret = np.zeros((max_len,), dtype=np.int32)\n",
    "    # actual encoding\n",
    "    ordinals = tokenizer.texts_to_sequences([s])[0][-max_len:]\n",
    "    encoded = np.array(ordinals, dtype=np.int32)\n",
    "    # take the 'tail' of the encoded and keep it\n",
    "    ret[-len(encoded):] = encoded\n",
    "    # formulate this into a very mini batch, only one batch entry\n",
    "    return np.expand_dims(ret, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0, 128,  70,  42]], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_string('Can we have')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_string(model_output):\n",
    "    return tokenizer.sequences_to_texts([[model_output.argmax().astype(np.int32)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['give']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_string(outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll make a keras callback, so we can watch text generation at each epoch as the model learns. Callbacks are a nice way to 'see inside' keras while it is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generate(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        text = 'Can we have'\n",
    "        for i in range(32):\n",
    "            output = self.model.predict(encode_string(text))\n",
    "            next_word = decode_string(output)[0]\n",
    "            text += ' {0}'.format(next_word)\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll do a bit more advanced learning -- and make a network that can encode and decode a recurrent string network.\n",
    "\n",
    "This starts with embedding the integer representing each word -- this turns an index of a single word into a floating point array better suited for machine learning. Then we run a recurrent network -- it loops over each word position, feeding the network into itself on each step. \n",
    "\n",
    "The next part of the stack is a standard multilayer perceptron. Here we're using the `elu` activation. This differs from a `relu` in that is will allow some negative values, where a `relu` is always zero for negative inputs.\n",
    "\n",
    "Finally, we do a dense output to generate one hot encodings for outputs via `softmax`.\n",
    "\n",
    "We're going to use Adam, since we had great learning results with it earlier -- it's a pretty good default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "268414/268414 [==============================] - 536s 2ms/step - loss: 7.3406\n",
      "Can we have been been in the world of the world of the world of the world of the world of the world of the world of the world of the world of the world\n",
      "Epoch 2/32\n",
      "268414/268414 [==============================] - 481s 2ms/step - loss: 6.6730\n",
      "Can we have a good man of the world the other time of the world and the other time the other time i was a good man and the other time i was a good\n",
      "Epoch 3/32\n",
      "268414/268414 [==============================] - 480s 2ms/step - loss: 6.3067\n",
      "Can we have forgotten to see the same for the same for the same for the same for the same place for the same place and the same time and the same time and the\n",
      "Epoch 4/32\n",
      "268414/268414 [==============================] - 480s 2ms/step - loss: 5.8960\n",
      "Can we have a good man of course he is in the dark and the last time they are all the same time they say he was in the same time he had the last\n",
      "Epoch 5/32\n",
      "268414/268414 [==============================] - 483s 2ms/step - loss: 5.3733\n",
      "Can we have you see the night of the night i am here for the gold cup of the duck private compton and the voice of the night and the voice of the church of\n",
      "Epoch 6/32\n",
      "268414/268414 [==============================] - 476s 2ms/step - loss: 4.7373\n",
      "Can we have you just go pat waiter waited for me to go to be seen on the light of the bar the sun i am the last time i was in the city arms\n",
      "Epoch 7/32\n",
      "268414/268414 [==============================] - 481s 2ms/step - loss: 4.0642\n",
      "Can we have no music have ears what you have no money to see the eat of your wash and shoulder melancholy god soft night i hate people no hate people like that damn it\n",
      "Epoch 8/32\n",
      "268414/268414 [==============================] - 478s 2ms/step - loss: 3.4666\n",
      "Can we have their bad feed like a corpse why golden else are you too bad for you feel that way feel a flower of god i hate the mention of the lamb bawling on\n",
      "Epoch 9/32\n",
      "268414/268414 [==============================] - 479s 2ms/step - loss: 2.9652\n",
      "Can we have their own touch me run over me tide at them outside the obituary notices they stuck the flies buzzed his downcast rising weighing the will probably about a word of beauty he\n",
      "Epoch 10/32\n",
      "268414/268414 [==============================] - 479s 2ms/step - loss: 2.5642\n",
      "Can we have you too much noise too wait wait till i wait awhile under all the dark wall come under love shall ere long enter into most mild light wait gentle summer fields —do\n",
      "Epoch 11/32\n",
      "268414/268414 [==============================] - 479s 2ms/step - loss: 2.2450\n",
      "Can we have dear gerald dear o dear o dear o dear o no dear for hamlet for me i am very well i have forgotten my eye retaining the perpendicular he staggers a pace\n",
      "Epoch 12/32\n",
      "268414/268414 [==============================] - 483s 2ms/step - loss: 1.9980\n",
      "Can we have their swimming eyes bloom elbowing through the crowd plucks stephen’s arm fizz and wine buck mulligan laid his cigarette from the presstable ben dollard lydia douce goulding collis ward ate steak and\n",
      "Epoch 13/32\n",
      "268414/268414 [==============================] - 477s 2ms/step - loss: 1.7952\n",
      "Can we have forgotten i bet on the feel of the heart of the girls i think i saw from the sea yet they come back through makes me feel all a year we have\n",
      "Epoch 14/32\n",
      "268414/268414 [==============================] - 482s 2ms/step - loss: 1.6402\n",
      "Can we have their drawbacks that bee or bluebottle too other day last do it’s not moving you see perhaps not now do you know how are you do you know how are things —hello\n",
      "Epoch 15/32\n",
      "268414/268414 [==============================] - 480s 2ms/step - loss: 1.5130\n",
      "Can we have forgotten perhaps feel the night felt they wound their ground in the doorway there is have no —no thats the bath now coming into the room with a married man in a\n",
      "Epoch 16/32\n",
      "268414/268414 [==============================] - 482s 2ms/step - loss: 1.4087\n",
      "Can we have light my lips feel me feel no more south now pity they can’t move before dressing kill it keep my kissed at first legs off colour after her cold water and jacket\n",
      "Epoch 17/32\n",
      "268414/268414 [==============================] - 479s 2ms/step - loss: 1.3244\n",
      "Can we have forgotten you feel i won’t eat you feel so hard with sweet soft muscles bloom uncloaks welt against her waist preposterous an old athos people boylan back loudly company ate shake and\n",
      "Epoch 18/32\n",
      "268414/268414 [==============================] - 480s 2ms/step - loss: 1.2572\n",
      "Can we have forgotten you feel so tide all day warm day saw their balance anywhere do it standing somewhere must be home forward i’ll knock you down there rush now fork and stop him\n",
      "Epoch 19/32\n",
      "268414/268414 [==============================] - 482s 2ms/step - loss: 1.1987\n",
      "Can we have forgotten it light the pianola i flew will hearing not hungry man zoe florry lynch the blond man watched the polished of the immaculate reciting the litany of our lady of loreto\n",
      "Epoch 20/32\n",
      "268414/268414 [==============================] - 477s 2ms/step - loss: 1.1523\n",
      "Can we have forgotten you rose and potato purse where one of them sees wind alone swift woman remember she lapped dear willun when she went with a crust in his hand a little trouble\n",
      "Epoch 21/32\n",
      "268414/268414 [==============================] - 482s 2ms/step - loss: 1.1142\n",
      "Can we have forgotten you feel the feel themselves i feel so young dream of songs on this mrs breen don’t she cried mind she sits twilight she thinks on her finger and molten drink\n",
      "Epoch 22/32\n",
      "268414/268414 [==============================] - 480s 2ms/step - loss: 1.0832\n",
      "Can we have forgotten singing she takes up bronze bishop juice positive isn’t a particular ring with opportunity all the dark the coffin was over stephen’s ear to be an irishman as it was altogether\n",
      "Epoch 23/32\n",
      "268414/268414 [==============================] - 481s 2ms/step - loss: 1.0525\n",
      "Can we have forgotten kevin egan not he them in denzille street full bottle of allsop slide five em meeting he pressed his right hand on the axle sadly over the shore at the open\n",
      "Epoch 24/32\n",
      "268414/268414 [==============================] - 474s 2ms/step - loss: 1.0282\n",
      "Can we have thou no one what’s going to catch out her shell row over it she gives her the coward’s blow they hurried forward behind with m’coy the other one pipe goes with the\n",
      "Epoch 25/32\n",
      "268414/268414 [==============================] - 478s 2ms/step - loss: 1.0117\n",
      "Can we have martha seven six i am —good john henry menton said i am quite right sir ugly no love we are one morning sir knows theres georges church bells and the lowest of\n",
      "Epoch 26/32\n",
      "268414/268414 [==============================] - 482s 2ms/step - loss: 0.9921\n",
      "Can we have tap tap tap tap tap tap tap tap virag her hand and shows coyly her boa exhausted her sort all now dear richie raised his hand aside way father conmee supposed a\n",
      "Epoch 27/32\n",
      "268414/268414 [==============================] - 483s 2ms/step - loss: 0.9795\n",
      "Can we have light fresh words evoke tomorrow will be a week no letter for me he knows him a little thing in his face quite safe but two days every man he felt me\n",
      "Epoch 28/32\n",
      "268414/268414 [==============================] - 482s 2ms/step - loss: 0.9593\n",
      "Can we have front me alone a couch by tram here he laughs her soft obligation is now a loud hot male big black panther the secret about the day o he laid down the\n",
      "Epoch 29/32\n",
      "268414/268414 [==============================] - 480s 2ms/step - loss: 0.9433\n",
      "Can we have light a girl bello lost my blood you have my blood you are too we feel must return through a breast at all i mean the united empire of a guilty substance\n",
      "Epoch 30/32\n",
      "268414/268414 [==============================] - 476s 2ms/step - loss: 0.9442\n",
      "Can we have light my wind i feel so feel pity named my enemy i just simply going of dark edward an arch pulled in his body don’t match by man for instance they get\n",
      "Epoch 31/32\n",
      "268414/268414 [==============================] - 482s 2ms/step - loss: 0.9263\n",
      "Can we have light a flower mrs bella cohen she gently met la la la la la la bella canebrake all slipperslappers with his ten fingers cropped up ben dollard lydia douce george lidwell pat\n",
      "Epoch 32/32\n",
      "268414/268414 [==============================] - 481s 2ms/step - loss: 0.9216\n",
      "Can we have end you’ll come to the right what’s left bloom they change the bat flew forth from the ivied belfry through the dusk hither thither with a lost property of dull times at\n"
     ]
    }
   ],
   "source": [
    "number_embedding_layers = 256\n",
    "number_hidden_layers = 256\n",
    "number_layers = 2\n",
    "epochs = 32\n",
    "batch_size = 32\n",
    "\n",
    "model = Sequential()\n",
    "# begin by embedding character positions\n",
    "model.add(Embedding(unique_tokens,\n",
    "                    number_embedding_layers, \n",
    "                    input_shape=(inputs.shape[1],)))\n",
    "# and then work on the embeddings recurrently\n",
    "model.add(LSTM(number_hidden_layers, unroll=True))\n",
    "model.add(Dense(number_hidden_layers, activation='elu'))\n",
    "model.add(Dense(number_hidden_layers, activation='elu'))\n",
    "model.add(Dense(outputs.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "results = model.fit(inputs, outputs, epochs=epochs, batch_size=batch_size, callbacks=[Generate()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(total_loss):\n",
    "    x_axis = np.linspace(0, len(total_loss), len(total_loss), endpoint=True)\n",
    "    plt.semilogy(x_axis, total_loss)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(results.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the loss keeps declining -- training for more epochs can certainly generate more learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
